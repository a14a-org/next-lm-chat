/**
 * Mock data service
 *
 * This service provides mock data for API responses when real API is not available.
 * Centralizing mock data makes it easier to maintain and update.
 */

/**
 * Mock models list
 */
export const mockModels = {
  object: 'list',
  data: [
    {
      id: 'local-model',
      name: 'LM Studio Local Model',
      created: Math.floor(Date.now() / 1000),
    },
    {
      id: 'gpt-4',
      name: 'GPT-4',
      created: 1687882411,
    },
    {
      id: 'gpt-3.5-turbo',
      name: 'GPT-3.5 Turbo',
      created: 1677649963,
    },
    {
      id: 'text-embedding-ada-002',
      name: 'Ada Embeddings v2',
      created: 1671217299,
    },
    {
      id: 'text-davinci-003',
      name: 'Davinci',
      created: 1669599635,
    },
  ],
};

/**
 * Generate a mock text completion response
 *
 * @param model - The model name
 * @param prompt - The input prompt
 * @returns Mock completion response
 */
export const generateMockCompletion = (model: string, prompt: string) => {
  return {
    id: 'cmpl-' + Date.now(),
    object: 'text_completion',
    created: Math.floor(Date.now() / 1000),
    model,
    choices: [
      {
        text: `This is a mock completion for: "${prompt}"\n\nIn a real implementation, this would be generated by an AI model.`,
        index: 0,
        logprobs: null,
        finish_reason: 'stop',
      },
    ],
    usage: {
      prompt_tokens: prompt.length,
      completion_tokens: 20,
      total_tokens: prompt.length + 20,
    },
  };
};

/**
 * Generate a mock chat completion response
 *
 * @param model - The model name
 * @param messages - The chat messages
 * @returns Mock chat completion response
 */
export const generateMockChatCompletion = (
  model: string,
  messages: Array<{ role: string; content: string }>
) => {
  const lastMessage = messages[messages.length - 1];
  const response = `This is a mock response to: "${lastMessage.content}"\n\nIn a real implementation, this would be generated by an AI model.`;

  return {
    id: 'chatcmpl-' + Date.now(),
    object: 'chat.completion',
    created: Math.floor(Date.now() / 1000),
    model,
    choices: [
      {
        index: 0,
        message: {
          role: 'assistant',
          content: response,
        },
        finish_reason: 'stop',
      },
    ],
    usage: {
      prompt_tokens: messages.reduce((sum, msg) => sum + msg.content.length, 0),
      completion_tokens: response.length,
      total_tokens: messages.reduce((sum, msg) => sum + msg.content.length, 0) + response.length,
    },
  };
};

/**
 * Generate mock embeddings
 *
 * @param model - The model name
 * @param inputs - The input texts
 * @returns Mock embeddings response
 */
export const generateMockEmbeddings = (model: string, inputs: string[]) => {
  return {
    object: 'list',
    data: inputs.map((input, i) => ({
      object: 'embedding',
      embedding: Array.from({ length: 10 }, () => Math.random() * 2 - 1), // 10-dim mock embedding
      index: i,
    })),
    model,
    usage: {
      prompt_tokens: inputs.reduce((acc, input) => acc + input.length, 0),
      total_tokens: inputs.reduce((acc, input) => acc + input.length, 0),
    },
  };
};
